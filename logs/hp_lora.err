INFO:    Setting 'NVIDIA_VISIBLE_DEVICES=all' to emulate legacy GPU binding.
INFO:    Setting --writable-tmpfs (required by nvidia-container-cli)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.50s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Parameter 'function'=<bound method HPLora.create_prompt of <models.lora.HPLora object at 0x14fd35491540>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/816 [00:00<?, ? examples/s]Map: 100%|██████████| 816/816 [00:00<00:00, 8312.88 examples/s]
Map:   0%|          | 0/816 [00:00<?, ? examples/s]Map: 100%|██████████| 816/816 [00:01<00:00, 724.01 examples/s]Map: 100%|██████████| 816/816 [00:01<00:00, 714.61 examples/s]
Filter:   0%|          | 0/816 [00:00<?, ? examples/s]Filter: 100%|██████████| 816/816 [00:00<00:00, 1283.04 examples/s]Filter: 100%|██████████| 816/816 [00:00<00:00, 1274.32 examples/s]
Map:   0%|          | 0/118 [00:00<?, ? examples/s]Map: 100%|██████████| 118/118 [00:00<00:00, 9026.59 examples/s]
Map:   0%|          | 0/118 [00:00<?, ? examples/s]Map: 100%|██████████| 118/118 [00:00<00:00, 1471.48 examples/s]
Filter:   0%|          | 0/118 [00:00<?, ? examples/s]Filter: 100%|██████████| 118/118 [00:00<00:00, 3241.98 examples/s]
/d/hpc/home/zk0821/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
  0%|          | 0/1000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Traceback (most recent call last):
  File "/d/hpc/home/zk0821/ul-fri-nlp-course-project-f1/src/hp_lora.py", line 5, in <module>
    hp_lora.fine_tune_model(verbose=True)
  File "/d/hpc/home/zk0821/ul-fri-nlp-course-project-f1/src/models/lora.py", line 186, in fine_tune_model
    self.peft_trainer.train()
  File "/d/hpc/home/zk0821/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 361, in train
    output = super().train(*args, **kwargs)
  File "/d/hpc/home/zk0821/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1780, in train
    return inner_training_loop(
  File "/d/hpc/home/zk0821/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2118, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/d/hpc/home/zk0821/.local/lib/python3.10/site-packages/transformers/trainer.py", line 3045, in training_step
    self.accelerator.backward(loss)
  File "/d/hpc/home/zk0821/.local/lib/python3.10/site-packages/accelerate/accelerator.py", line 2013, in backward
    loss.backward(**kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py", line 289, in apply
    return user_fn(self, *args)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 319, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 31.74 GiB of which 911.06 MiB is free. Including non-PyTorch memory, this process has 30.85 GiB memory in use. Of the allocated memory 28.65 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 0/1000 [00:18<?, ?it/s]
srun: error: wn203: task 0: Exited with exit code 1
